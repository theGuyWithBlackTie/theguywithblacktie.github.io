---
layout: post
title: 'DSPy Breakdown - Part 2: Optimizing Prompts'
date: 2025-07-19 11:00 +0530
math: true
description: 'Learnings how to use DSPy to optimze prompts for LMs'
toc: true
image:
    path: assets/headers/dspy-header.png
    alt: DSPy
hidden: true
categories: [LLMs, DSPy]
tags: [context engineering, frameworks, prompt optimization]
---

In the [previous part](https://ashishsinghal.ai/posts/dspy-part-1/), we learned the basic fundamentals of DSPy, which is, how to configure the language models globally, how to inference through DSPy through `Signatures` and `Modules`. In this part, we will learn how to optimize or finetune the prompt for different LMs.

DSPy syntax is inspired from PyTorch, hence I will be refencing PyTorch modules to explain DSPy.

## `Example`
A machine learning model is trained or optimized using labeled data, where input data is fed to the model and its weights are adjusted to produce outputs that closely match the corresponding target labels. Simlarly, in prompt optimization a labeled data is used and prompt's language (or text) are adjusted to produce the expected output.

A prompt an be viewed as a proxy for a machine learning model, where modifying the prompt text is analogous to adjusting the model's weights, as it influences the behaviour and output of the underlying model.
 
While training a deep learning model in PyTorch, the data is typically represented using the `Datasets` class. Similarly, in DSPy, data used for prompt optimization is represented using the `Example` class.